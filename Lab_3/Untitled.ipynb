{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2432e454-f290-429c-bd5b-784e9004cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ceca722-e7ab-4acd-8afe-6abc4123aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = datasets.mnist.load_data()\n",
    "x_train = tf.pad(x_train, [[0, 0], [2,2], [2,2]])/255\n",
    "x_test = tf.pad(x_test, [[0, 0], [2,2], [2,2]])/255\n",
    "x_train = tf.expand_dims(x_train, axis=3, name=None)\n",
    "x_test = tf.expand_dims(x_test, axis=3, name=None)\n",
    "x_train = tf.repeat(x_train, 3, axis=3)\n",
    "x_test = tf.repeat(x_test, 3, axis=3)\n",
    "x_val = x_train[-2000:,:,:,:]\n",
    "y_val = y_train[-2000:]\n",
    "x_train = x_train[:-2000,:,:,:]\n",
    "y_train = y_train[:-2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4233114f-2c88-44cb-822d-2ea961612856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resizing (Resizing)          (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 56, 56, 96)        34944     \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 56, 56, 96)        0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 56, 56, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 256)         614656    \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 1, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1, 1, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 1, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1, 1, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 1, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 21,622,154\n",
      "Trainable params: 21,622,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"bilinear\", input_shape=x_train.shape[1:]))\n",
    "model.add(layers.Conv2D(96, 11, strides=4, padding='same'))\n",
    "model.add(layers.Lambda(tf.nn.local_response_normalization))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(3, strides=2))\n",
    "model.add(layers.Conv2D(256, 5, strides=4, padding='same'))\n",
    "model.add(layers.Lambda(tf.nn.local_response_normalization))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(3, strides=2))\n",
    "model.add(layers.Conv2D(384, 3, strides=4, padding='same'))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Conv2D(384, 3, strides=4, padding='same'))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Conv2D(256, 3, strides=4, padding='same'))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4de1f937-7677-4470-ae5a-5f5f29fb4766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 0.5082 - accuracy: 0.7812 - val_loss: 23.7827 - val_accuracy: 0.1875\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 12.0343 - accuracy: 0.2188 - val_loss: 7.2851 - val_accuracy: 0.2812\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 1.8080 - accuracy: 0.5625 - val_loss: 4.1839 - val_accuracy: 0.2812\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 1.5237 - accuracy: 0.4375 - val_loss: 7.3041 - val_accuracy: 0.2188\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 3.1167 - accuracy: 0.4062 - val_loss: 5.4566 - val_accuracy: 0.2188\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 2.3767 - accuracy: 0.4375 - val_loss: 3.3828 - val_accuracy: 0.2812\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 1.4977 - accuracy: 0.4688 - val_loss: 2.6051 - val_accuracy: 0.2500\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 1.2507 - accuracy: 0.5312 - val_loss: 2.4697 - val_accuracy: 0.2188\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 1.1324 - accuracy: 0.5938 - val_loss: 2.4432 - val_accuracy: 0.2500\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 1.2261 - accuracy: 0.5312 - val_loss: 2.3765 - val_accuracy: 0.2812\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 1.3057 - accuracy: 0.3438 - val_loss: 2.2757 - val_accuracy: 0.2500\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 1.3084 - accuracy: 0.4062 - val_loss: 2.1728 - val_accuracy: 0.2500\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 1.2496 - accuracy: 0.4688 - val_loss: 2.0777 - val_accuracy: 0.2188\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 1.2128 - accuracy: 0.5625 - val_loss: 1.9937 - val_accuracy: 0.2188\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 1.1872 - accuracy: 0.5312 - val_loss: 1.9152 - val_accuracy: 0.2812\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 1.1150 - accuracy: 0.5938 - val_loss: 1.8447 - val_accuracy: 0.3438\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 1.0305 - accuracy: 0.6875 - val_loss: 1.8104 - val_accuracy: 0.3125\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 1.0346 - accuracy: 0.6875 - val_loss: 1.8366 - val_accuracy: 0.3125\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 1.0139 - accuracy: 0.5625 - val_loss: 1.8563 - val_accuracy: 0.3125\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.9836 - accuracy: 0.5625 - val_loss: 1.8633 - val_accuracy: 0.3438\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.9582 - accuracy: 0.5312 - val_loss: 1.9513 - val_accuracy: 0.3438\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.8817 - accuracy: 0.5625 - val_loss: 2.0538 - val_accuracy: 0.3125\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.8339 - accuracy: 0.6562 - val_loss: 2.0926 - val_accuracy: 0.2812\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.8175 - accuracy: 0.6562 - val_loss: 2.0731 - val_accuracy: 0.3125\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.7301 - accuracy: 0.7188 - val_loss: 2.0326 - val_accuracy: 0.3750\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.7247 - accuracy: 0.6250 - val_loss: 2.0295 - val_accuracy: 0.4062\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.6808 - accuracy: 0.6562 - val_loss: 2.1016 - val_accuracy: 0.4375\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.6271 - accuracy: 0.7500 - val_loss: 2.2429 - val_accuracy: 0.4062\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5872 - accuracy: 0.7500 - val_loss: 2.5341 - val_accuracy: 0.4062\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5468 - accuracy: 0.8125 - val_loss: 2.8874 - val_accuracy: 0.3750\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.4716 - accuracy: 0.8438 - val_loss: 3.1348 - val_accuracy: 0.3438\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.4644 - accuracy: 0.8125 - val_loss: 3.2881 - val_accuracy: 0.4062\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.4223 - accuracy: 0.8125 - val_loss: 3.4607 - val_accuracy: 0.4375\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.3617 - accuracy: 0.8750 - val_loss: 3.7503 - val_accuracy: 0.3750\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.2859 - accuracy: 0.9062 - val_loss: 4.4406 - val_accuracy: 0.3125\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.2596 - accuracy: 0.9375 - val_loss: 5.4376 - val_accuracy: 0.2812\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.2111 - accuracy: 1.0000 - val_loss: 5.2549 - val_accuracy: 0.3125\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.1751 - accuracy: 0.9688 - val_loss: 6.2578 - val_accuracy: 0.3125\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.1927 - accuracy: 0.9375 - val_loss: 7.9946 - val_accuracy: 0.3125\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1868 - accuracy: 0.9375 - val_loss: 7.1830 - val_accuracy: 0.3750\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.1408 - accuracy: 0.9375 - val_loss: 7.6336 - val_accuracy: 0.3125\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.0903 - accuracy: 1.0000 - val_loss: 8.6724 - val_accuracy: 0.2812\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.0919 - accuracy: 0.9688 - val_loss: 9.3688 - val_accuracy: 0.3125\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.1420 - accuracy: 0.9375 - val_loss: 10.2493 - val_accuracy: 0.3750\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.1168 - accuracy: 0.9688 - val_loss: 11.2136 - val_accuracy: 0.4062\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0970 - accuracy: 0.9375 - val_loss: 9.9242 - val_accuracy: 0.4062\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.1625 - accuracy: 0.9375 - val_loss: 10.4417 - val_accuracy: 0.3750\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.0747 - accuracy: 0.9688 - val_loss: 11.7745 - val_accuracy: 0.3438\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.0745 - accuracy: 0.9688 - val_loss: 13.7696 - val_accuracy: 0.3750\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.1055 - accuracy: 0.9375 - val_loss: 12.9541 - val_accuracy: 0.3125\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.1168 - accuracy: 0.9375 - val_loss: 10.5192 - val_accuracy: 0.3438\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.2837 - accuracy: 0.8438 - val_loss: 12.9888 - val_accuracy: 0.3125\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 15.0884 - val_accuracy: 0.3438\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c544f7ae986d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/jup_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jup_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jup_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jup_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jup_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/jup_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jup_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "history = model.fit(x_train[:32], y_train[:32], batch_size=32, epochs=100, validation_data=(x_val[:32], y_val[:32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9da15b-a4a4-442e-8d92-e8194989ab5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3.1 - Сверточные нейронные сети (Convolutional Neural Networks)\n",
    "\n",
    "Это последнее задание на numpy, вы до него дожили! Остался последний марш-бросок, дальше только PyTorch.\n",
    "\n",
    "В этом задании вы реализуете свою собственную сверточную нейронную сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer, ConvolutionalLayer, MaxPoolingLayer, Flattener\n",
    "from model import ConvNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD, Adam\n",
    "from metrics import multiclass_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "На этот раз мы не будем их преобразовывать в один вектор, а оставим размерности (num_samples, 32, 32, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_X = train_X.astype(np.float) / 255.0\n",
    "    test_X = test_X.astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_X, axis = 0)\n",
    "    train_X -= mean_image\n",
    "    test_X -= mean_image\n",
    "    return train_X, test_X\n",
    "    \n",
    "train_X, test_X = prepare_for_neural_network(x_train, x_test)\n",
    "# Split train into train and val\n",
    "train_X, val_X, train_y, val_y = train_test_split(train_X, y_train, random_state=42, test_size=0.3)\n",
    "test_y = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_X = train_X.reshape((-1, 28, 28, 1))\n",
    "val_X = val_X.reshape((-1, 28, 28, 1))\n",
    "test_X = test_X.reshape((-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 28, 28, 1), (18000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, val_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оптимизатор и код для тренировки \n",
    "Должен заработать с кодом из прошлого задания без изменений!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ConvNet(input_shape=(28,28,1), n_output_classes=10, conv1_channels=2, conv2_channels=2)\n",
    "# dataset = Dataset(train_X[:16], train_y[:16], val_X[:16], val_y[:16])\n",
    "# trainer = Trainer(model, dataset, SGD(), batch_size=16, learning_rate=1e-4)\n",
    "\n",
    "# loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(train_history)\n",
    "# plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итак, оверфитим маленький набор данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottle_resized = resize(bottle, (140, 54))\n",
    "\n",
    "# def resize(arr, shape):\n",
    "#     # img = cv2.imread('your_image.jpg')\n",
    "#     res = cv2.resize(arr, dsize=shape, interpolation=cv2.INTER_CUBIC)\n",
    "#     return res\n",
    "    \n",
    "# train_X_resized = train_X.repeat(8, axis=1).repeat(8, axis=2)\n",
    "# val_X_resized = val_X.repeat(8, axis=1).repeat(8, axis=2)\n",
    "# train_X_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 224, 224, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_resized = train_X[:128].repeat(8, axis=1).repeat(8, axis=2)\n",
    "val_X_resized = val_X[:128].repeat(8, axis=1).repeat(8, axis=2)\n",
    "train_X_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 84, 84, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_resized = train_X[:128].repeat(3, axis=1).repeat(3, axis=2)\n",
    "val_X_resized = val_X[:128].repeat(3, axis=1).repeat(3, axis=2)\n",
    "train_X_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(np.array([1, np.nan])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.612551, Train accuracy: 0.187500, val accuracy: 0.000000\n",
      "Loss: 5.612551, Train accuracy: 0.125000, val accuracy: 0.125000\n",
      "Loss: 6.044286, Train accuracy: 0.062500, val accuracy: 0.062500\n",
      "Loss: 6.476021, Train accuracy: 0.062500, val accuracy: 0.062500\n",
      "Loss: 6.476021, Train accuracy: 0.250000, val accuracy: 0.250000\n",
      "Loss: 5.180816, Train accuracy: 0.187500, val accuracy: 0.000000\n",
      "Loss: 5.612551, Train accuracy: 0.062500, val accuracy: 0.125000\n",
      "Loss: 6.476021, Train accuracy: 0.062500, val accuracy: 0.125000\n",
      "Loss: 6.476021, Train accuracy: 0.125000, val accuracy: 0.125000\n",
      "Loss: 6.044286, Train accuracy: 0.062500, val accuracy: 0.250000\n",
      "Loss: 6.476021, Train accuracy: 0.312500, val accuracy: 0.125000\n",
      "Loss: 4.749082, Train accuracy: 0.187500, val accuracy: 0.000000\n",
      "Loss: 5.612551, Train accuracy: 0.250000, val accuracy: 0.062500\n",
      "Loss: 5.180816, Train accuracy: 0.062500, val accuracy: 0.062500\n",
      "Loss: 6.476021, Train accuracy: 0.125000, val accuracy: 0.062500\n",
      "Loss: 6.044286, Train accuracy: 0.125000, val accuracy: 0.125000\n",
      "Loss: 6.044286, Train accuracy: 0.187500, val accuracy: 0.125000\n",
      "Loss: 5.612551, Train accuracy: 0.250000, val accuracy: 0.062500\n",
      "Loss: 5.180816, Train accuracy: 0.062500, val accuracy: 0.062500\n",
      "Loss: 6.476021, Train accuracy: 0.250000, val accuracy: 0.125000\n",
      "Loss: 5.180816, Train accuracy: 0.125000, val accuracy: 0.062500\n",
      "Loss: 6.044286, Train accuracy: 0.187500, val accuracy: 0.000000\n",
      "Loss: 5.612551, Train accuracy: 0.312500, val accuracy: 0.062500\n",
      "Loss: 4.749082, Train accuracy: 0.437500, val accuracy: 0.187500\n",
      "Loss: 3.885612, Train accuracy: 0.375000, val accuracy: 0.062500\n",
      "Loss: 4.317347, Train accuracy: 0.437500, val accuracy: 0.250000\n",
      "Loss: 3.885612, Train accuracy: 0.562500, val accuracy: 0.062500\n",
      "Loss: 3.022143, Train accuracy: 0.187500, val accuracy: 0.187500\n",
      "Loss: 5.612551, Train accuracy: 0.437500, val accuracy: 0.187500\n",
      "Loss: 3.885612, Train accuracy: 0.437500, val accuracy: 0.062500\n",
      "Loss: 3.885612, Train accuracy: 0.562500, val accuracy: 0.062500\n",
      "Loss: 3.022143, Train accuracy: 0.312500, val accuracy: 0.187500\n",
      "Loss: 4.749082, Train accuracy: 0.562500, val accuracy: 0.125000\n",
      "Loss: 3.022143, Train accuracy: 0.625000, val accuracy: 0.125000\n",
      "Loss: 2.590408, Train accuracy: 0.687500, val accuracy: 0.187500\n",
      "Loss: 2.158674, Train accuracy: 0.500000, val accuracy: 0.187500\n",
      "Loss: 3.453878, Train accuracy: 0.812500, val accuracy: 0.062500\n",
      "Loss: 1.295204, Train accuracy: 0.562500, val accuracy: 0.125000\n",
      "Loss: 3.022143, Train accuracy: 0.500000, val accuracy: 0.125000\n",
      "Loss: 3.453878, Train accuracy: 0.937500, val accuracy: 0.125000\n",
      "Loss: 0.431735, Train accuracy: 0.875000, val accuracy: 0.250000\n",
      "Loss: 0.863469, Train accuracy: 0.875000, val accuracy: 0.187500\n",
      "Loss: 0.863469, Train accuracy: 0.750000, val accuracy: 0.187500\n",
      "Loss: 1.726939, Train accuracy: 0.937500, val accuracy: 0.312500\n",
      "Loss: 0.431735, Train accuracy: 0.937500, val accuracy: 0.250000\n",
      "Loss: 0.431735, Train accuracy: 1.000000, val accuracy: 0.250000\n",
      "Loss: -0.000000, Train accuracy: 1.000000, val accuracy: 0.250000\n",
      "Loss: -0.000000, Train accuracy: 0.937500, val accuracy: 0.250000\n",
      "Loss: 0.431735, Train accuracy: 1.000000, val accuracy: 0.125000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-36c7c965f23a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ML_course/Lab_3/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mave_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             train_accuracy = self.compute_accuracy(self.dataset.train_X,\n\u001b[0m\u001b[1;32m    114\u001b[0m                                                    self.dataset.train_y)\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ML_course/Lab_3/trainer.py\u001b[0m in \u001b[0;36mcompute_accuracy\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_indices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mbatch_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mpred_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ML_course/Lab_3/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# You can probably copy the code from previous assignment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ML_course/Lab_3/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'slice_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_W\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'slice_w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_W\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jup_env/lib/python3.8/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     36\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     37\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_size = 16\n",
    "model = ConvNet(input_shape=(224,224,1), n_output_classes=10, conv1_channels=40, conv2_channels=40)\n",
    "dataset = Dataset(train_X_resized[:data_size], train_y[:data_size], val_X_resized[:data_size], val_y[:data_size])\n",
    "# model = ConvNet(input_shape=(28,28,1), n_output_classes=10, conv1_channels=40, conv2_channels=40)\n",
    "# dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "\n",
    "trainer = Trainer(model, dataset, Adam(), learning_rate=1e-3, num_epochs=100, batch_size=16)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
